{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"./data/train-data_all/fr.dev.json\", \"r\") as file_handler:\n",
    "    dataset = json.load(file_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "sgns = [i['char'] for i in dataset]\n",
    "glosses = [i['gloss'] for i in dataset]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# Import DATA\n",
    "with open(\"./data/lemm2Idx.json\") as outfile:\n",
    "    lemm2Idx = json.load(outfile)\n",
    "\n",
    "with open(\"./data/idx2Lemm.json\") as outfile:\n",
    "    idx2Lemm = json.load(outfile)\n",
    "\n",
    "with open(\"./data/lemmatized_glosses.json\") as outfile:\n",
    "    lemmatized_glosses = json.load(outfile)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "lemmatized_glosses_text = []\n",
    "\n",
    "for gloss in lemmatized_glosses:\n",
    "    text = \"\"\n",
    "    for word in gloss:\n",
    "        text += idx2Lemm[str(word)] + \" \"\n",
    "    lemmatized_glosses_text.append(text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(1,), dtype=\"string\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "max_tokens = len(lemm2Idx)\n",
    "#max_len = max([len(i) for i in lemmatized_glosses_text])\n",
    "max_len = 50\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    # Max vocab size. Any words outside of the max_tokens most common ones\n",
    "    # will be treated the same way: as \"out of vocabulary\" (OOV) tokens.\n",
    "    max_tokens=max_tokens,\n",
    "    # Output integer indices, one per string token\n",
    "    output_mode=\"int\",\n",
    "    # Always pad or truncate to exactly this many tokens\n",
    "    output_sequence_length=max_len,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Call adapt(), which fits the TextVectorization layer to our text dataset.\n",
    "# This is when the max_tokens most common words (i.e. the vocabulary) are selected.\n",
    "vectorize_layer.adapt(np.array(list(idx2Lemm.values())))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "model.add(vectorize_layer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, Flatten\n",
    "\n",
    "# Note that we're using max_tokens + 1 here, since there's an\n",
    "# out-of-vocabulary (OOV) token that gets added to the vocab.\n",
    "model.add(Embedding(max_tokens + 1, 64))\n",
    "\n",
    "model.add(Bidirectional(LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2), merge_mode = 'concat'))\n",
    "\n",
    "model.add(LSTM(units=256, return_sequences=False, dropout=0.5, recurrent_dropout=0.5))\n",
    "\n",
    "#model.add(TimeDistributed(Dense(256, activation=\"relu\")))\n",
    "\n",
    "model.add(Dense(256))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_2 (TextV  (None, 50)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 50, 64)            554176    \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 50, 256)          197632    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,342,912\n",
      "Trainable params: 1,342,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "200/200 [==============================] - 133s 633ms/step - loss: 737.3497 - accuracy: 0.0298\n",
      "Epoch 2/25\n",
      "200/200 [==============================] - 119s 597ms/step - loss: 652.9429 - accuracy: 0.0000e+00\n",
      "Epoch 3/25\n",
      "200/200 [==============================] - 118s 588ms/step - loss: 650.8094 - accuracy: 0.0000e+00\n",
      "Epoch 4/25\n",
      "200/200 [==============================] - 118s 589ms/step - loss: 640.4029 - accuracy: 0.0000e+00\n",
      "Epoch 5/25\n",
      "200/200 [==============================] - 119s 593ms/step - loss: 645.4492 - accuracy: 0.0000e+00\n",
      "Epoch 6/25\n",
      "200/200 [==============================] - 116s 580ms/step - loss: 652.4534 - accuracy: 0.0000e+00\n",
      "Epoch 7/25\n",
      "200/200 [==============================] - 116s 581ms/step - loss: 642.5391 - accuracy: 0.0000e+00\n",
      "Epoch 8/25\n",
      "200/200 [==============================] - 116s 581ms/step - loss: 630.9207 - accuracy: 0.0000e+00\n",
      "Epoch 9/25\n",
      "200/200 [==============================] - 115s 575ms/step - loss: 634.3755 - accuracy: 0.0000e+00\n",
      "Epoch 10/25\n",
      "200/200 [==============================] - 115s 575ms/step - loss: 647.1017 - accuracy: 0.0000e+00\n",
      "Epoch 11/25\n",
      "200/200 [==============================] - 114s 571ms/step - loss: 591.6851 - accuracy: 0.0000e+00\n",
      "Epoch 12/25\n",
      "200/200 [==============================] - 115s 573ms/step - loss: 683.2219 - accuracy: 0.0000e+00\n",
      "Epoch 13/25\n",
      "200/200 [==============================] - 114s 570ms/step - loss: 641.1297 - accuracy: 0.0000e+00\n",
      "Epoch 14/25\n",
      "200/200 [==============================] - 114s 570ms/step - loss: 662.6998 - accuracy: 0.0000e+00\n",
      "Epoch 15/25\n",
      "200/200 [==============================] - 114s 568ms/step - loss: 653.0279 - accuracy: 0.0000e+00\n",
      "Epoch 16/25\n",
      "200/200 [==============================] - 114s 570ms/step - loss: 638.0639 - accuracy: 0.0000e+00\n",
      "Epoch 17/25\n",
      "200/200 [==============================] - 114s 570ms/step - loss: 581.2746 - accuracy: 0.0000e+00\n",
      "Epoch 18/25\n",
      "200/200 [==============================] - 114s 569ms/step - loss: 638.7783 - accuracy: 0.0000e+00\n",
      "Epoch 19/25\n",
      "200/200 [==============================] - 116s 582ms/step - loss: 645.7509 - accuracy: 0.0000e+00\n",
      "Epoch 20/25\n",
      "200/200 [==============================] - 114s 569ms/step - loss: 689.4919 - accuracy: 0.0000e+00\n",
      "Epoch 21/25\n",
      "200/200 [==============================] - 114s 570ms/step - loss: 653.6433 - accuracy: 0.0000e+00\n",
      "Epoch 22/25\n",
      "200/200 [==============================] - 114s 569ms/step - loss: 631.9559 - accuracy: 0.0000e+00\n",
      "Epoch 23/25\n",
      "200/200 [==============================] - 113s 567ms/step - loss: 633.3565 - accuracy: 0.0000e+00\n",
      "Epoch 24/25\n",
      "200/200 [==============================] - 114s 569ms/step - loss: 625.5060 - accuracy: 0.0000e+00\n",
      "Epoch 25/25\n",
      "200/200 [==============================] - 113s 566ms/step - loss: 604.5687 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "results = pd.DataFrame()\n",
    "results['with_add_lstm'] = model.fit(lemmatized_glosses_text, sgns, epochs=25)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}